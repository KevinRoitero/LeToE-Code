{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import isfile, join\n",
    "\n",
    "COLLECTIONS = ['TREC3', 'TREC5', 'TREC6', 'TREC7', 'TREC8', 'TREC2001', 'R04', 'TB06', 'TB06M', 'WEB14']\n",
    "CSV_TABLE_PATH = '../../src/Tables/'\n",
    "RUN_PATH = '../../run/'\n",
    "QRELS_PATH = '../../src/qrels/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Read runs and build a pool using only the top 100 documents retrieved for each topic\n",
    "'''\n",
    "def get_pools(systems, topics, RUN_PATH, top=False):\n",
    "    df_pool = pd.DataFrame()\n",
    "    for i_system, system in enumerate(systems):\n",
    "        file = 'input.{}'.format(system)\n",
    "        print('system {}'.format(system))\n",
    "        file_content = pd.read_csv(join(RUN_PATH, file + '.gz'), compression='gzip', header=None, delimiter=r\"\\s+\")\n",
    "        file_content.columns = ['topic', 'zero', 'doc', 'rank', 'rel_value', 'system']\n",
    "        file_content.drop('zero', 1, inplace=True)\n",
    "        file_content['topic'] = file_content['topic'].astype(str)\n",
    "        file_content['system'] = file_content['system'].astype(str)\n",
    "        if top:\n",
    "            for i_topic, topic in enumerate(topics):\n",
    "                file_content_top = file_content[file_content['topic'] == str(topic)]\n",
    "                file_content_top = file_content_top.head(100)\n",
    "                df_pool = df_pool.append(file_content_top, ignore_index=True)\n",
    "        else:\n",
    "            df_pool = df_pool.append(file_content, ignore_index=True)\n",
    "    return df_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Build \"our\" qrels taking the top 100 documents retrieved by each system on each topic, form a pool with them and remove\n",
    "duplicates. To compute mu and sigma, use the relevance given to a document in the real qrels (if the document is not\n",
    "there, then the document gets removed)\n",
    "'''\n",
    "for collection in COLLECTIONS:\n",
    "    real_table = pd.read_csv(CSV_TABLE_PATH + collection + '.csv', sep=',', header=0, index_col=0)\n",
    "    systems = real_table.index.values\n",
    "    topics = real_table.columns.values\n",
    "    \n",
    "    df_run = get_pools(systems, topics, RUN_PATH + collection, top=True)\n",
    "    df_run.drop(['rel_value', 'system', 'rank'], axis=1, inplace=True)\n",
    "    df_run['topic'] = df_run['topic'].astype(str)\n",
    "    df_run.set_index('topic', inplace=True)\n",
    "    \n",
    "    qrels = pd.read_csv(QRELS_PATH + 'qrels.' + collection + '.txt', sep=' ', header=None)\n",
    "    qrels.columns = ['topic', 'zero', 'doc', 'relevant']\n",
    "    qrels['topic'] = qrels['topic'].astype(str)\n",
    "    qrels.set_index('topic', inplace=True)\n",
    "    \n",
    "    new_qrels = pd.DataFrame()\n",
    "    means = []\n",
    "    for topic in pd.unique(df_run.index.values):\n",
    "        df_run_sub = df_run.loc[topic]\n",
    "        df_run_sub.drop_duplicates(keep='first', inplace=True)\n",
    "        qrels_sub = qrels.loc[topic]\n",
    "        \n",
    "        df_merged = df_run_sub.merge(qrels_sub, on='doc', how='left')\n",
    "        df_merged.fillna({'topic': topic, 'relevant': 0}, inplace=True)\n",
    "        df_merged.dropna(axis=0, inplace=True)\n",
    "        df_merged['relevant'] = df_merged['relevant'].astype(int)\n",
    "        \n",
    "        means.append(np.mean(df_merged['relevant']))\n",
    "    \n",
    "    print(collection, len(topics), np.mean(means), np.std(means))\n",
    "    # assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Compute mu and sigma using real qrels\n",
    "'''\n",
    "for collection in COLLECTIONS:\n",
    "    qrels = pd.read_csv(QRELS_PATH + 'qrels.' + collection + '.txt', sep=' ', header=None)\n",
    "    qrels.columns = ['topic', 'zero', 'doc', 'relevant']\n",
    "    qrels.set_index('topic', inplace=True)\n",
    "    means = []\n",
    "    for topic in pd.unique(qrels.index.values):\n",
    "        qrels_sub = qrels.loc[topic]\n",
    "        means.append(round(np.mean(qrels_sub['relevant']), 2))\n",
    "    print(collection, 100 * np.mean(means), round(np.std(means), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
